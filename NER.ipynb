{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a31cf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import medspacy\n",
    "\n",
    "from medspacy.ner import TargetMatcher, TargetRule\n",
    "from medspacy.visualization import visualize_ent, visualize_dep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5aea64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable={\"ner\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff6a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd7cd7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'medspacy_pyrush',\n",
       " 'medspacy_target_matcher',\n",
       " 'medspacy_context']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\harih\\Downloads\\discharge_summary.txt\") as f:\n",
    "    text = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8fd876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load(medspacy_enable=[\"medspacy_pyrush\", \"medspacy_target_matcher\"])\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f3c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_rules = [\n",
    "    TargetRule(literal=\"abdominal pain\", category=\"PROBLEM\"),\n",
    "    TargetRule(\"stroke\", \"PROBLEM\"),\n",
    "    TargetRule(\"hemicolectomy\", \"TREATMENT\"),\n",
    "    TargetRule(\"Hydrochlorothiazide\", \"TREATMENT\"),\n",
    "    TargetRule(\"colon cancer\", \"PROBLEM\"),\n",
    "    TargetRule(\"metastasis\", \"PROBLEM\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58f5cade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-08 12:33:53.362\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 0 'Admission' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 15 '             ' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 15-15 (idx 33-33) between spans 32-46\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.366\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 15 '             ' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.368\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 16 'Discharge' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.369\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 31 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.370\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 31-31 (idx 78-78) between spans 78-80\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.370\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 31 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.371\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 32 'Date' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.374\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 48 '            ' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.376\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 48-48 (idx 112-112) between spans 111-124\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.378\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 48 '            ' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.380\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 49 'Sex' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.382\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 53 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.383\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 53-53 (idx 132-132) between spans 132-134\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.384\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 53 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.385\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 54 'Service' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.388\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 57 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.389\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 57-57 (idx 150-150) between spans 150-152\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 57 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.392\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 58 'Allergies' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 60 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.397\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 60-60 (idx 162-162) between spans 162-163\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 60 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 61 'Hydrochlorothiazide' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.401\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 62 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 62-62 (idx 182-182) between spans 182-184\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 62 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.405\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 63 'Attending:[**First' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.406\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 72 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.409\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 72-72 (idx 221-221) between spans 221-222\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.409\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 72 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.412\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 73 'Chief' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.412\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 76 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.415\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 76-76 (idx 238-238) between spans 238-239\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.417\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 76 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.419\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 77 'Abdominal' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.422\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 79 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.422\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 79-79 (idx 253-253) between spans 253-255\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.430\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 79 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 80 'Major' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.433\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 86 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.435\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 86-86 (idx 292-292) between spans 292-293\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.438\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 86 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.439\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 87 'PICC' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.440\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 98 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.441\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 98-98 (idx 313-313) between spans 313-314\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.442\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 98 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.444\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 99 'ERCP' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.445\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 111 '\n",
      "\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.446\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 111-111 (idx 347-347) between spans 347-350\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 111 '\n",
      "\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.451\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 112 'History' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.454\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 117 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.456\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 117-117 (idx 377-377) between spans 377-378\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.458\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 117 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.459\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 118 '74y' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.461\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 142 'Imaging' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.463\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 142 'Imaging' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.464\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 149 'She' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.465\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 149 'She' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.468\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 156 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.471\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 156-156 (idx 562-562) between spans 562-564\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.473\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 156 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.474\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 157 'Past' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.477\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 161 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.478\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 161-161 (idx 585-585) between spans 585-586\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.478\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 161 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.480\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 162 '1' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.480\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 185 'Last' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.481\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 185 'Last' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.482\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 202 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.482\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 202-202 (idx 725-725) between spans 725-726\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.484\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 202 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.485\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 203 '2' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.486\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 209 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.487\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 209-209 (idx 754-754) between spans 754-755\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.489\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 209 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.490\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 210 '3' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.492\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 213 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.493\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 213-213 (idx 770-770) between spans 770-772\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.494\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 213 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.495\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 214 'Social' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.496\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 217 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.497\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 217-217 (idx 787-787) between spans 787-788\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.498\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 217 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.499\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 218 'Married' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.500\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 224 'No' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.501\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 224 'No' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.502\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 230 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.506\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 230-230 (idx 840-840) between spans 840-842\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.507\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 230 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.508\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 231 'Family' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.509\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 234 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.511\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 234-234 (idx 857-857) between spans 857-858\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.512\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 234 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.513\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 235 'Mother' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.515\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 246 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.516\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 246-246 (idx 904-904) between spans 904-905\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.518\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 246 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.519\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 247 '2' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.521\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 250 '\n",
      "\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.523\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 250-250 (idx 925-925) between spans 925-928\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.525\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 250 '\n",
      "\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.526\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 251 'Brief' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.527\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 255 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.529\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 255-255 (idx 950-950) between spans 950-951\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.530\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 255 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.531\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 256 'Ms.' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.532\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 299 'She' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.533\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 299 'She' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.534\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 306 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.535\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 306-306 (idx 1156-1156) between spans 1156-1157\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.537\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 306 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.538\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 307 'Discharge' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.540\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 310 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.541\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 310-310 (idx 1179-1179) between spans 1179-1180\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.541\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 310 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.542\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 311 '1' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.544\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 318 'Sig' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.546\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 318 'Sig' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.557\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 338 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.561\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 338-338 (idx 1270-1270) between spans 1270-1271\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.563\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 338 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.569\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 339 '2' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.575\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 351 'Sig' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.581\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 351 'Sig' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.587\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 367 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.589\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 367-367 (idx 1365-1365) between spans 1365-1366\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.591\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 367 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.592\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 368 '3' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.594\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 375 'Sig' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.595\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 375 'Sig' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.597\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 397 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.604\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 397-397 (idx 1456-1456) between spans 1456-1458\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.606\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 397 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.609\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 398 'Discharge' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.611\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 401 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.613\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 401-401 (idx 1478-1478) between spans 1478-1479\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.615\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 401 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.616\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 402 'Type' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.618\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 407 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 407-407 (idx 1501-1501) between spans 1501-1502\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.621\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 407 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.623\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 408 'HTN' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.625\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 416 '\n",
      "\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.626\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 416-416 (idx 1541-1541) between spans 1541-1544\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.627\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 416 '\n",
      "\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.628\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 417 'Discharge' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.630\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 420 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.631\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 420-420 (idx 1567-1567) between spans 1567-1568\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.633\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 420 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.634\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 421 'Patient' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.635\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 425 'Please' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.639\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 425 'Please' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.642\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 476 'A' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.644\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 476 'A' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.645\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 477 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.646\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 477-477 (idx 1823-1823) between spans 1823-1825\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.647\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 477 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.648\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 478 'Completed' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.650\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 529 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.652\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 529-529 (idx 1960-1960) between spans 1960-1961\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 529 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.654\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 530 'Signed' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.656\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 575 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.657\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 575-575 (idx 2088-2088) between spans 2088-2089\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.658\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 575 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.660\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 576 '(' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:33:53.664\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] Token/tag mapping: [(Admission, True), (Date, False), (:, False), ( , False), ([, False), (*, False), (*, False), (2573, False), (-, False), (5, False), (-, False), (30, False), (*, False), (*, False), (], False), (             , True), (Discharge, True), (Date, False), (:, False), (  , False), ([, False), (*, False), (*, False), (2573, False), (-, False), (7, False), (-, False), (1, False), (*, False), (*, False), (], False), (\n",
      "\n",
      ", True), (Date, True), (of, False), (Birth, False), (:, False), ( , False), ([, False), (*, False), (*, False), (2498, False), (-, False), (8, False), (-, False), (19, False), (*, False), (*, False), (], False), (            , True), (Sex, True), (:, False), (  , False), (F, False), (\n",
      "\n",
      ", True), (Service, True), (:, False), (SURGERY, False), (\n",
      "\n",
      ", True), (Allergies, True), (:, False), (\n",
      ", True), (Hydrochlorothiazide, True), (\n",
      "\n",
      ", True), (Attending:[**First, True), (Name3, False), ((, False), (LF, False), (), False), (1893, False), (*, False), (*, False), (], False), (\n",
      ", True), (Chief, True), (Complaint, False), (:, False), (\n",
      ", True), (Abdominal, True), (pain, False), (\n",
      "\n",
      ", True), (Major, True), (Surgical, False), (or, False), (Invasive, False), (Procedure, False), (:, False), (\n",
      ", True), (PICC, True), (line, False), ([, False), (*, False), (*, False), (6, False), (-, False), (25, False), (*, False), (*, False), (], False), (\n",
      ", True), (ERCP, True), (w/, False), (sphincterotomy, False), ([, False), (*, False), (*, False), (5, False), (-, False), (31, False), (*, False), (*, False), (], False), (\n",
      "\n",
      "\n",
      ", True), (History, True), (of, False), (Present, False), (Illness, False), (:, False), (\n",
      ", True), (74y, True), (female, False), (with, False), (type, False), (2, False), (dm, False), (and, False), (a, False), (recent, False), (stroke, False), (affecting, False), (her, False), (\n",
      ", False), (speech, False), (,, False), (who, False), (presents, False), (with, False), (2, False), (days, False), (of, False), (abdominal, False), (pain, False), (., False), (Imaging, True), (shows, False), (no, False), (evidence, False), (of, False), (metastasis, False), (., False), (She, True), (is, False), (not, False), (receiving, False), (any, False), (chemo, False), (., False), (\n",
      "\n",
      ", True), (Past, True), (Medical, False), (History, False), (:, False), (\n",
      ", True), (1, True), (., False), (Colon, False), (cancer, False), (dx'd, False), (in, False), ([, False), (*, False), (*, False), (2554, False), (*, False), (*, False), (], False), (,, False), (tx'd, False), (with, False), (hemicolectomy, False), (,, False), (XRT, False), (,, False), (\n",
      ", False), (chemo, False), (., False), (Last, True), (colonoscopy, False), (showed, False), (:, False), (Last, False), (CEA, False), (was, False), (in, False), (the, False), (8, False), (range, False), (\n",
      ", False), ((, False), (down, False), (from, False), (9, False), (), False), (\n",
      ", True), (2, True), (., False), (Type, False), (II, False), (Diabetes, False), (Mellitus, False), (\n",
      ", True), (3, True), (., False), (Hypertension, False), (\n",
      "\n",
      ", True), (Social, True), (History, False), (:, False), (\n",
      ", True), (Married, True), (,, False), (former, False), (tobacco, False), (use, False), (., False), (No, True), (alcohol, False), (or, False), (drug, False), (use, False), (., False), (\n",
      "\n",
      ", True), (Family, True), (History, False), (:, False), (\n",
      ", True), (Mother, True), (with, False), (stroke, False), (at, False), (age, False), (82, False), (., False), (no, False), (early, False), (deaths, False), (., False), (\n",
      ", True), (2, True), (daughters-, False), (healthy, False), (\n",
      "\n",
      "\n",
      ", True), (Brief, True), (Hospital, False), (Course, False), (:, False), (\n",
      ", True), (Ms., True), ([, False), (*, False), (*, False), (Known, False), (patient, False), (lastname, False), (2004, False), (*, False), (*, False), (], False), (was, False), (admitted, False), (on, False), ([, False), (*, False), (*, False), (2573, False), (-, False), (5, False), (-, False), (30, False), (*, False), (*, False), (], False), (., False), (Ultrasound, False), (at, False), (the, False), (time, False), (of, False), (\n",
      ", False), (admission, False), (demonstrated, False), (pancreatic, False), (duct, False), (dilitation, False), (and, False), (an, False), (\n",
      ", False), (edematous, False), (gallbladder, False), (., False), (She, True), (was, False), (admitted, False), (to, False), (the, False), (ICU, False), (., False), (\n",
      ", True), (Discharge, True), (Medications, False), (:, False), (\n",
      ", True), (1, True), (., False), (Miconazole, False), (Nitrate, False), (2, False), (%, False), (Powder, False), (Sig, True), (:, False), (One, False), ((, False), (1, False), (), False), (Appl, False), (Topical, False), ( , False), (BID, False), (\n",
      ", False), ((, False), (2, False), (times, False), (a, False), (day, False), (), False), (as, False), (needed, False), (., False), (\n",
      ", True), (2, True), (., False), (Heparin, False), (Sodium, False), ((, False), (Porcine, False), (), False), (5,000, False), (unit, False), (/, False), (mL, False), (Solution, False), (Sig, True), (:, False), (One, False), ((, False), (1, False), (), False), (\n",
      ", False), (Injection, False), (TID, False), ((, False), (3, False), (times, False), (a, False), (day, False), (), False), (., False), (\n",
      ", True), (3, True), (., False), (Acetaminophen, False), (160, False), (mg/5, False), (mL, False), (Elixir, False), (Sig, True), (:, False), (One, False), ((, False), (1, False), (), False), ( , False), (PO, False), (Q4, False), (-, False), (6H, False), (\n",
      ", False), ((, False), (every, False), (4, False), (to, False), (6, False), (hours, False), (), False), (as, False), (needed, False), (., False), (\n",
      "\n",
      ", True), (Discharge, True), (Diagnosis, False), (:, False), (\n",
      ", True), (Type, True), (2, False), (DM, False), (\n",
      ", False), (Pancreatitis, False), (\n",
      ", True), (HTN, True), (\n",
      ", False), (h, False), (/, False), (o, False), (aspiration, False), (respiratory, False), (distress, False), (\n",
      "\n",
      "\n",
      ", True), (Discharge, True), (Instructions, False), (:, False), (\n",
      ", True), (Patient, True), (may, False), (shower, False), (., False), (Please, True), (call, False), (your, False), (surgeon, False), (or, False), (return, False), (to, False), (the, False), (\n",
      ", False), (emergency, False), (room, False), (if, False), ([, False), (*, False), (*, False), (Doctor, False), (First, False), (Name, False), (*, False), (*, False), (], False), (experience, False), (fever, False), (>, False), (101.5, False), (,, False), (nausea, False), (,, False), (vomiting, False), (,, False), (\n",
      ", False), (abdominal, False), (pain, False), (,, False), (shortness, False), (of, False), (breath, False), (,, False), (abdominal, False), (pain, False), (or, False), (any, False), (\n",
      ", False), (significant, False), ( , False), (change, False), (in, False), (your, False), (medical, False), (condition, False), (., False), (A, True), (\n",
      "\n",
      ", True), (Completed, True), (by, False), (:, False), ([, False), (*, False), (*, False), (First, False), (Name11, False), ((, False), (Name, False), (Pattern1, False), (), False), (2010, False), (*, False), (*, False), (], False), ([, False), (*, False), (*, False), (Last, False), (Name, False), ((, False), (NamePattern1, False), (), False), (2011, False), (*, False), (*, False), (], False), (MD, False), ([, False), (*, False), (*, False), (MD, False), (Number, False), (2012, False), (*, False), (*, False), (], False), ([, False), (*, False), (*, False), (2573, False), (-, False), (7, False), (-, False), (1, False), (*, False), (*, False), (], False), (@, False), (1404, False), (\n",
      ", True), (Signed, True), (electronically, False), (by, False), (:, False), (DR, False), (., False), ([, False), (*, False), (*, False), (First, False), (Name8, False), ((, False), (NamePattern2, False), (), False), (*, False), (*, False), (], False), ([, False), (*, False), (*, False), (Last, False), (Name, False), ((, False), (NamePattern1, False), (), False), (*, False), (*, False), (], False), (\n",
      " , False), (on, False), (:, False), (FRI, False), ([, False), (*, False), (*, False), (2573, False), (-, False), (7, False), (-, False), (2, False), (*, False), (*, False), (], False), (8:03, False), (AM, False), (\n",
      ", True), ((, True), (End, False), (of, False), (Report, False), (), False)]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Hydrochlorothiazide, Abdominal pain, stroke, abdominal pain, metastasis, Colon cancer, hemicolectomy, stroke, abdominal pain, abdominal pain)\n"
     ]
    }
   ],
   "source": [
    "target_matcher.add(target_rules)\n",
    "doc = nlp(text)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a7a0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hydrochlorothiazide  |  TREATMENT  |  TargetRule(literal=\"Hydrochlorothiazide\", category=\"TREATMENT\", pattern=None, attributes=None, on_match=None)\n",
      "Abdominal pain  |  PROBLEM  |  TargetRule(literal=\"abdominal pain\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n",
      "stroke  |  PROBLEM  |  TargetRule(literal=\"stroke\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n",
      "abdominal pain  |  PROBLEM  |  TargetRule(literal=\"abdominal pain\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n",
      "metastasis  |  PROBLEM  |  TargetRule(literal=\"metastasis\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n",
      "Colon cancer  |  PROBLEM  |  TargetRule(literal=\"colon cancer\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n",
      "hemicolectomy  |  TREATMENT  |  TargetRule(literal=\"hemicolectomy\", category=\"TREATMENT\", pattern=None, attributes=None, on_match=None)\n",
      "stroke  |  PROBLEM  |  TargetRule(literal=\"stroke\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n",
      "abdominal pain  |  PROBLEM  |  TargetRule(literal=\"abdominal pain\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n",
      "abdominal pain  |  PROBLEM  |  TargetRule(literal=\"abdominal pain\", category=\"PROBLEM\", pattern=None, attributes=None, on_match=None)\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent, ent.label_, ent._.target_rule, sep=\"  |  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e4f0c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-08 12:45:31.625\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 1 'Past' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.626\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 5 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.629\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] GAP DETECTED: tokens 5-5 (idx 22-22) between spans 22-23\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.630\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 5 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.630\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 6 '1' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.633\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 10 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.634\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] GAP DETECTED: tokens 10-10 (idx 45-45) between spans 45-46\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.634\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 10 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.636\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 11 '2' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.636\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 17 '\n",
      "\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.637\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] GAP DETECTED: tokens 17-17 (idx 74-74) between spans 74-76\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.638\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 17 '\n",
      "\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.639\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 18 'Assessment' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.640\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 22 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.641\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] GAP DETECTED: tokens 22-22 (idx 96-96) between spans 96-97\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.644\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 22 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.646\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 23 'There' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.648\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 30 'Continue' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.649\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 30 'Continue' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.650\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 35 'Follow' marked as sentence start (span end next token)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.651\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 35 'Follow' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.652\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 44 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.653\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] [doc 0] Token 44 '\n",
      "' marked as sentence start (whitespace after all spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 12:45:31.655\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=1] Token/tag mapping: [(\n",
      ", False), (Past, True), (Medical, False), (History, False), (:, False), (\n",
      ", True), (1, True), (., False), (Atrial, False), (fibrillation, False), (\n",
      ", True), (2, True), (., False), (Type, False), (II, False), (Diabetes, False), (Mellitus, False), (\n",
      "\n",
      ", True), (Assessment, True), (and, False), (Plan, False), (:, False), (\n",
      ", True), (There, True), (is, False), (no, False), (evidence, False), (of, False), (pneumonia, False), (., False), (Continue, True), (warfarin, False), (for, False), (Afib, False), (., False), (Follow, True), (up, False), (for, False), (management, False), (of, False), (type, False), (2, False), (DM, False), (., False), (\n",
      ", True)]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['medspacy_pyrush', 'medspacy_target_matcher', 'medspacy_context']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"><br>Past Medical History:<br>1. \n",
       "<mark class=\"entity\" style=\"background: #1f77b4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Atrial fibrillation\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROBLEM</span>\n",
       "</mark>\n",
       "<br>2. \n",
       "<mark class=\"entity\" style=\"background: #1f77b4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Type II Diabetes Mellitus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROBLEM</span>\n",
       "</mark>\n",
       "<br><br>Assessment and Plan:<br>There is \n",
       "<mark class=\"entity\" style=\"background: #2ca02c; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    no evidence of\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NEGATED_EXISTENCE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #1f77b4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pneumonia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROBLEM</span>\n",
       "</mark>\n",
       ". Continue \n",
       "<mark class=\"entity\" style=\"background: #ff7f0e; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    warfarin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MEDICATION</span>\n",
       "</mark>\n",
       " for \n",
       "<mark class=\"entity\" style=\"background: #1f77b4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Afib\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROBLEM</span>\n",
       "</mark>\n",
       ". Follow up for management of \n",
       "<mark class=\"entity\" style=\"background: #1f77b4; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    type 2 DM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PROBLEM</span>\n",
       "</mark>\n",
       ".<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load medspacy model\n",
    "nlp = medspacy.load()\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "text = \"\"\"\n",
    "Past Medical History:\n",
    "1. Atrial fibrillation\n",
    "2. Type II Diabetes Mellitus\n",
    "\n",
    "Assessment and Plan:\n",
    "There is no evidence of pneumonia. Continue warfarin for Afib. Follow up for management of type 2 DM.\n",
    "\"\"\"\n",
    "\n",
    "# Add rules for target concept extraction\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_rules = [\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\"),\n",
    "    TargetRule(\"atrial fibrillation\", \"PROBLEM\", pattern=[{\"LOWER\": \"afib\"}]),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"Type II Diabetes Mellitus\", \"PROBLEM\", \n",
    "              pattern=[\n",
    "                  {\"LOWER\": \"type\"},\n",
    "                  {\"LOWER\": {\"IN\": [\"2\", \"ii\", \"two\"]}},\n",
    "                  {\"LOWER\": {\"IN\": [\"dm\", \"diabetes\"]}},\n",
    "                  {\"LOWER\": \"mellitus\", \"OP\": \"?\"}\n",
    "              ]),\n",
    "    TargetRule(\"warfarin\", \"MEDICATION\")\n",
    "]\n",
    "target_matcher.add(target_rules)\n",
    "\n",
    "doc = nlp(text)\n",
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb006d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harih\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " was founded by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Steve Jobs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cupertino\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple was founded by Steve Jobs in Cupertino.\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876946f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f6a586f040b548bfaf9d5c36ce316b66-0\" class=\"displacy\" width=\"1250\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">founded</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">by</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Steve</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">Jobs</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Cupertino.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6a586f040b548bfaf9d5c36ce316b66-0-0\" stroke-width=\"2px\" d=\"M62,152.0 62,102.0 350.0,102.0 350.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6a586f040b548bfaf9d5c36ce316b66-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,154.0 L58,146.0 66,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6a586f040b548bfaf9d5c36ce316b66-0-1\" stroke-width=\"2px\" d=\"M212,152.0 212,127.0 347.0,127.0 347.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6a586f040b548bfaf9d5c36ce316b66-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,154.0 L208,146.0 216,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6a586f040b548bfaf9d5c36ce316b66-0-2\" stroke-width=\"2px\" d=\"M362,152.0 362,127.0 497.0,127.0 497.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6a586f040b548bfaf9d5c36ce316b66-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">agent</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M497.0,154.0 L501.0,146.0 493.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6a586f040b548bfaf9d5c36ce316b66-0-3\" stroke-width=\"2px\" d=\"M662,152.0 662,127.0 797.0,127.0 797.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6a586f040b548bfaf9d5c36ce316b66-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,154.0 L658,146.0 666,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6a586f040b548bfaf9d5c36ce316b66-0-4\" stroke-width=\"2px\" d=\"M512,152.0 512,102.0 800.0,102.0 800.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6a586f040b548bfaf9d5c36ce316b66-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M800.0,154.0 L804.0,146.0 796.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6a586f040b548bfaf9d5c36ce316b66-0-5\" stroke-width=\"2px\" d=\"M812,152.0 812,127.0 947.0,127.0 947.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6a586f040b548bfaf9d5c36ce316b66-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M947.0,154.0 L951.0,146.0 943.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f6a586f040b548bfaf9d5c36ce316b66-0-6\" stroke-width=\"2px\" d=\"M962,152.0 962,127.0 1097.0,127.0 1097.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f6a586f040b548bfaf9d5c36ce316b66-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1097.0,154.0 L1101.0,146.0 1093.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple was founded by Steve Jobs in Cupertino.\")\n",
    "\n",
    "displacy.render(doc, style=\"dep\", jupyter=True, options={\"compact\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120646f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-08 22:57:06.394\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 1 'The' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 11 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.397\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 11-11 (idx 64-64) between spans 63-65\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.398\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 11 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.400\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 12 'History' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.401\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 18 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.403\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] GAP DETECTED: tokens 18-18 (idx 107-107) between spans 106-108\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 18 '\n",
      "' marked as sentence start (whitespace in gap between spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.405\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 19 'Recent' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.406\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 27 '\n",
      "' marked as sentence start (span end whitespace)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.407\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] [doc 0] Token 27 '\n",
      "' marked as sentence start (whitespace after all spans)\u001b[0m\n",
      "\u001b[32m2025-09-08 22:57:06.408\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=0] Token/tag mapping: [(\n",
      ", False), (The, True), (patient, False), (denies, False), (having, False), (diabetes, False), (but, False), (reports, False), (abdominal, False), (pain, False), (., False), (\n",
      ", True), (History, True), (shows, False), (a, False), (cerebrovascular, False), (accident, False), (., False), (\n",
      ", True), (Recent, True), (imaging, False), (shows, False), (metastasis, False), (in, False), (the, False), (liver, False), (., False), (\n",
      ", True)]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Problem: Abdominal Pain\n",
      " Specialist: Gastroenterologist\n",
      " Doctor: Dr. Bhartia Mithun\n",
      " Contact: +91-9012345678\n",
      " Location: Kamrup Metropolitan, Assam\n",
      "\n",
      " Problem: Abdominal Pain\n",
      " Specialist: General Physician\n",
      " Doctor: Dr. Renu Sharma\n",
      " Contact: +91-9090909090\n",
      " Location: Bengaluru, Karnataka\n",
      "\n",
      " Problem: Cerebrovascular Accident\n",
      " Specialist: Neurologist\n",
      " Doctor: Dr. Alafiya Meditour\n",
      " Contact: +91-9876543210\n",
      " Location: Gurugram, Haryana\n",
      "\n",
      " Problem: Metastasis\n",
      " Specialist: Oncologist\n",
      " Doctor: Dr. Amit Choraria\n",
      " Contact: +91-9988776655\n",
      " Location: Kolkata, West Bengal\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "from medspacy.visualization import visualize_ent\n",
    "\n",
    "# Step 2: Load medspaCy pipeline with ConText (negation/uncertainty handling)\n",
    "nlp = medspacy.load(\n",
    "    medspacy_enable=[\"medspacy_pyrush\", \"medspacy_target_matcher\", \"medspacy_context\"]\n",
    ")\n",
    "\n",
    "# Step 3: Define TargetRules with synonyms (PROBLEM entities only)\n",
    "problem_rules = [\n",
    "    TargetRule(\"stroke\", \"PROBLEM\"),\n",
    "    TargetRule(\"cerebrovascular accident\", \"PROBLEM\"),\n",
    "    TargetRule(\"diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"type 2 diabetes mellitus\", \"PROBLEM\"),\n",
    "    TargetRule(\"colon cancer\", \"PROBLEM\"),\n",
    "    TargetRule(\"colorectal carcinoma\", \"PROBLEM\"),\n",
    "    TargetRule(\"abdominal pain\", \"PROBLEM\"),\n",
    "    TargetRule(\"stomach ache\", \"PROBLEM\"),\n",
    "    TargetRule(\"metastasis\", \"PROBLEM\"),\n",
    "    TargetRule(\"tumor spread\", \"PROBLEM\"),\n",
    "]\n",
    "\n",
    "# Step 4: Add rules to the TargetMatcher\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_matcher.add(problem_rules)\n",
    "\n",
    "# Step 5: Problem-to-specialty mapping (support multiple specialties)\n",
    "problem_to_specialty = {\n",
    "    \"stroke\": [\"Neurologist\"],\n",
    "    \"cerebrovascular accident\": [\"Neurologist\"],\n",
    "    \"diabetes\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"type 2 diabetes mellitus\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"colon cancer\": [\"Oncologist\", \"Gastroenterologist\"],\n",
    "    \"colorectal carcinoma\": [\"Oncologist\", \"Gastroenterologist\"],\n",
    "    \"abdominal pain\": [\"Gastroenterologist\", \"General Physician\"],\n",
    "    \"stomach ache\": [\"Gastroenterologist\", \"General Physician\"],\n",
    "    \"metastasis\": [\"Oncologist\"],\n",
    "    \"tumor spread\": [\"Oncologist\"]\n",
    "}\n",
    "\n",
    "# Step 6: Specialist directory\n",
    "specialist_directory = {\n",
    "    \"Neurologist\": {\n",
    "        \"name\": \"Dr. Alafiya Meditour\",\n",
    "        \"contact\": \"+91-9876543210\",\n",
    "        \"location\": \"Gurugram, Haryana\"\n",
    "    },\n",
    "    \"Endocrinologist\": {\n",
    "        \"name\": \"Dr. Anshul Kumar\",\n",
    "        \"contact\": \"+91-9123456780\",\n",
    "        \"location\": \"West Delhi, Delhi\"\n",
    "    },\n",
    "    \"General Physician\": {\n",
    "        \"name\": \"Dr. Renu Sharma\",\n",
    "        \"contact\": \"+91-9090909090\",\n",
    "        \"location\": \"Bengaluru, Karnataka\"\n",
    "    },\n",
    "    \"Oncologist\": {\n",
    "        \"name\": \"Dr. Amit Choraria\",\n",
    "        \"contact\": \"+91-9988776655\",\n",
    "        \"location\": \"Kolkata, West Bengal\"\n",
    "    },\n",
    "    \"Gastroenterologist\": {\n",
    "        \"name\": \"Dr. Bhartia Mithun\",\n",
    "        \"contact\": \"+91-9012345678\",\n",
    "        \"location\": \"Kamrup Metropolitan, Assam\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 7: Sample clinical text\n",
    "text = \"\"\"\n",
    "The patient denies having diabetes but reports abdominal pain. \n",
    "History shows a cerebrovascular accident. \n",
    "Recent imaging shows metastasis in the liver.\n",
    "\"\"\"\n",
    "\n",
    "# Step 8: Process the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Step 9: Extract valid PROBLEM entities (ignore negated/uncertain ones)\n",
    "problems = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PROBLEM\":\n",
    "        if hasattr(ent._, \"is_negated\") and ent._.is_negated:\n",
    "            continue   # skip negated problems\n",
    "        problems.append(ent.text.lower())\n",
    "\n",
    "# Step 10: Map problems to specialists and display results\n",
    "for problem in problems:\n",
    "    specialties = problem_to_specialty.get(problem, [])\n",
    "    if specialties:\n",
    "        for specialty in specialties:\n",
    "            doctor = specialist_directory.get(specialty)\n",
    "            if doctor:\n",
    "                print(f\"\\n Problem: {problem.title()}\")\n",
    "                print(f\" Specialist: {specialty}\")\n",
    "                print(f\" Doctor: {doctor['name']}\")\n",
    "                print(f\" Contact: {doctor['contact']}\")\n",
    "                print(f\" Location: {doctor['location']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7665fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-08 23:01:33.452\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=2] [doc 0] Token 0 'liver' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-08 23:01:33.454\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=2] Token/tag mapping: [(liver, True), (failure, False), (kidney, False), (stones, False)]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " No active problems detected from input.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "\n",
    "# Step 2: Load medspaCy pipeline with ConText (negation handling)\n",
    "nlp = medspacy.load(\n",
    "    medspacy_enable=[\"medspacy_pyrush\", \"medspacy_target_matcher\", \"medspacy_context\"]\n",
    ")\n",
    "\n",
    "# Step 3: Define TargetRules with synonyms (PROBLEM entities only)\n",
    "problem_rules = [\n",
    "    TargetRule(\"stroke\", \"PROBLEM\"),\n",
    "    TargetRule(\"cerebrovascular accident\", \"PROBLEM\"),\n",
    "    TargetRule(\"diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"type 2 diabetes mellitus\", \"PROBLEM\"),\n",
    "    TargetRule(\"colon cancer\", \"PROBLEM\"),\n",
    "    TargetRule(\"colorectal carcinoma\", \"PROBLEM\"),\n",
    "    TargetRule(\"abdominal pain\", \"PROBLEM\"),\n",
    "    TargetRule(\"stomach ache\", \"PROBLEM\"),\n",
    "    TargetRule(\"metastasis\", \"PROBLEM\"),\n",
    "    TargetRule(\"tumor spread\", \"PROBLEM\"),\n",
    "    TargetRule(\"hypertension\", \"PROBLEM\"),\n",
    "    TargetRule(\"high blood pressure\", \"PROBLEM\"),\n",
    "    TargetRule(\"heart attack\", \"PROBLEM\"),\n",
    "    TargetRule(\"myocardial infarction\", \"PROBLEM\"),\n",
    "    TargetRule(\"asthma\", \"PROBLEM\"),\n",
    "    TargetRule(\"chronic obstructive pulmonary disease\", \"PROBLEM\"),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"tuberculosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"kidney failure\", \"PROBLEM\"),\n",
    "    TargetRule(\"renal failure\", \"PROBLEM\"),\n",
    "    TargetRule(\"liver cirrhosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"hepatitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"thyroid disorder\", \"PROBLEM\"),\n",
    "    TargetRule(\"hypothyroidism\", \"PROBLEM\"),\n",
    "    TargetRule(\"migraine\", \"PROBLEM\"),\n",
    "    TargetRule(\"epilepsy\", \"PROBLEM\"),\n",
    "]\n",
    "\n",
    "# Step 4: Add rules to the TargetMatcher\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_matcher.add(problem_rules)\n",
    "\n",
    "# Step 5: Problem-to-specialty mapping (multi-specialties allowed)\n",
    "problem_to_specialty = {\n",
    "    \"stroke\": [\"Neurologist\"],\n",
    "    \"cerebrovascular accident\": [\"Neurologist\"],\n",
    "    \"diabetes\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"type 2 diabetes mellitus\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"colon cancer\": [\"Oncologist\", \"Gastroenterologist\"],\n",
    "    \"colorectal carcinoma\": [\"Oncologist\", \"Gastroenterologist\"],\n",
    "    \"abdominal pain\": [\"Gastroenterologist\", \"General Physician\"],\n",
    "    \"stomach ache\": [\"Gastroenterologist\", \"General Physician\"],\n",
    "    \"metastasis\": [\"Oncologist\"],\n",
    "    \"tumor spread\": [\"Oncologist\"],\n",
    "    \"hypertension\": [\"Cardiologist\", \"General Physician\"],\n",
    "    \"high blood pressure\": [\"Cardiologist\", \"General Physician\"],\n",
    "    \"heart attack\": [\"Cardiologist\"],\n",
    "    \"myocardial infarction\": [\"Cardiologist\"],\n",
    "    \"asthma\": [\"Pulmonologist\"],\n",
    "    \"chronic obstructive pulmonary disease\": [\"Pulmonologist\"],\n",
    "    \"pneumonia\": [\"Pulmonologist\"],\n",
    "    \"tuberculosis\": [\"Pulmonologist\"],\n",
    "    \"kidney failure\": [\"Nephrologist\"],\n",
    "    \"renal failure\": [\"Nephrologist\"],\n",
    "    \"liver cirrhosis\": [\"Hepatologist\"],\n",
    "    \"hepatitis\": [\"Hepatologist\"],\n",
    "    \"thyroid disorder\": [\"Endocrinologist\"],\n",
    "    \"hypothyroidism\": [\"Endocrinologist\"],\n",
    "    \"migraine\": [\"Neurologist\"],\n",
    "    \"epilepsy\": [\"Neurologist\"],\n",
    "}\n",
    "\n",
    "# Step 6: Specialist directory (expanded)\n",
    "specialist_directory = {\n",
    "    \"Neurologist\": {\n",
    "        \"name\": \"Dr. Alafiya Meditour\",\n",
    "        \"contact\": \"+91-9876543210\",\n",
    "        \"location\": \"Gurugram, Haryana\"\n",
    "    },\n",
    "    \"Endocrinologist\": {\n",
    "        \"name\": \"Dr. Anshul Kumar\",\n",
    "        \"contact\": \"+91-9123456780\",\n",
    "        \"location\": \"West Delhi, Delhi\"\n",
    "    },\n",
    "    \"General Physician\": {\n",
    "        \"name\": \"Dr. Renu Sharma\",\n",
    "        \"contact\": \"+91-9090909090\",\n",
    "        \"location\": \"Bengaluru, Karnataka\"\n",
    "    },\n",
    "    \"Oncologist\": {\n",
    "        \"name\": \"Dr. Amit Choraria\",\n",
    "        \"contact\": \"+91-9988776655\",\n",
    "        \"location\": \"Kolkata, West Bengal\"\n",
    "    },\n",
    "    \"Gastroenterologist\": {\n",
    "        \"name\": \"Dr. Bhartia Mithun\",\n",
    "        \"contact\": \"+91-9012345678\",\n",
    "        \"location\": \"Kamrup Metropolitan, Assam\"\n",
    "    },\n",
    "    \"Cardiologist\": {\n",
    "        \"name\": \"Dr. Priya Mehta\",\n",
    "        \"contact\": \"+91-9345678901\",\n",
    "        \"location\": \"Mumbai, Maharashtra\"\n",
    "    },\n",
    "    \"Pulmonologist\": {\n",
    "        \"name\": \"Dr. Sameer Bansal\",\n",
    "        \"contact\": \"+91-9456123789\",\n",
    "        \"location\": \"Jaipur, Rajasthan\"\n",
    "    },\n",
    "    \"Nephrologist\": {\n",
    "        \"name\": \"Dr. Kavita Deshmukh\",\n",
    "        \"contact\": \"+91-9988223344\",\n",
    "        \"location\": \"Chennai, Tamil Nadu\"\n",
    "    },\n",
    "    \"Hepatologist\": {\n",
    "        \"name\": \"Dr. Rajiv Kapoor\",\n",
    "        \"contact\": \"+91-9876501234\",\n",
    "        \"location\": \"Hyderabad, Telangana\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Step 7: Get user input\n",
    "text = input(\"Enter clinical text: \")\n",
    "\n",
    "# Step 8: Process the input text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Step 9: Extract valid PROBLEM entities (skip negated)\n",
    "problems = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PROBLEM\":\n",
    "        if hasattr(ent._, \"is_negated\") and ent._.is_negated:\n",
    "            continue\n",
    "        problems.append(ent.text.lower())\n",
    "\n",
    "# Step 10: Map problems to specialists and display results\n",
    "if not problems:\n",
    "    print(\"\\n No active problems detected from input.\")\n",
    "else:\n",
    "    for problem in problems:\n",
    "        specialties = problem_to_specialty.get(problem, [])\n",
    "        if specialties:\n",
    "            for specialty in specialties:\n",
    "                doctor = specialist_directory.get(specialty)\n",
    "                if doctor:\n",
    "                    print(f\"\\n Problem: {problem.title()}\")\n",
    "                    print(f\" Specialist: {specialty}\")\n",
    "                    print(f\" Doctor: {doctor['name']}\")\n",
    "                    print(f\" Contact: {doctor['contact']}\")\n",
    "                    print(f\" Location: {doctor['location']}\")\n",
    "        else:\n",
    "            print(f\"\\n No specialist found for problem: {problem.title()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0167a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Import necessary libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmedspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmedspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetRule\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Step 2: Load medspaCy pipeline with ConText (negation handling)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m components\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m set_extensions, get_extensions, get_doc_extensions, get_span_extensions, get_token_extensions\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\components.py:13\u001b[0m\n\u001b[0;32m      1\u001b[0m ALL_PIPE_NAMES \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentencizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget_matcher\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_consumer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m }\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentence_splitting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PyRuSHSentencizer\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_matcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetMatcher\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConText\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_tokenizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_medspacy_tokenizer\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\target_matcher\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_matcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetMatcher\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_rule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetRule\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcept_tagger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConceptTagger\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\target_matcher\\target_matcher.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc, Span\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget_rule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TargetRule\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmedspacy_matcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MedspacyMatcher\n\u001b[0;32m     12\u001b[0m \u001b[38;5;129m@Language\u001b[39m\u001b[38;5;241m.\u001b[39mfactory(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_target_matcher\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTargetMatcher\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    TargetMatcher is a component for advanced direction-based text extraction. Rules are defined using\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    `medspacy.target_matcher.TargetRule`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    TargetRule which set it.\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\common\\medspacy_matcher.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_rule\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRule\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregex_matcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexMatcher\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prune_overlapping_matches\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# suppress warnings here because the matchers warn if no patterns are specified, but since multiple matchers are\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# included that is not necessarily bad.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\common\\regex_matcher.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Matcher\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_token_for_char\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# we warn here but i'm not sure it's necessary.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# warnings.filterwarnings(\"once\", \"You are using a TargetRule with a regex pattern.*\")\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRegexMatcher\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\common\\util.py:10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union, Tuple, List\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Doc, Span, Token\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tuple_overlaps\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspan_contains\u001b[39m(\n\u001b[0;32m     14\u001b[0m     span: Union[Doc, Span],\n\u001b[0;32m     15\u001b[0m     target: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     16\u001b[0m     regex: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m     case_insensitive: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     18\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    Return True if a Span object contains a target phrase.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m        case_insensitive: Whether the matching is case-insensitive. Default is True.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\medspacy\\util.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Language\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mquickumls\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spacy_component\n\u001b[0;32m     16\u001b[0m DEFAULT_PIPE_NAMES \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_pyrush\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_target_matcher\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_context\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m ALL_PIPE_NAMES \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_preprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedspacy_doc_consumer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\quickumls\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m QuickUMLS\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_quickumls_client\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\quickumls\\core.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# installed modules\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munidecode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unidecode\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# project modules\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\__init__.py:146\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjsontags\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# PACKAGES\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassify\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\chunk\\__init__.py:155\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Natural Language Toolkit: Chunkers\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (C) 2001-2024 NLTK Project\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# For license information, see LICENSE.TXT\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mClasses and interfaces for identifying non-overlapping linguistic\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03mgroups (such as base noun phrases) in unrestricted text.  This task is\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;124;03m     pattern is valid.\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkParserI\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnamed_entity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Maxent_NE_Chunker\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregexp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RegexpChunkParser, RegexpParser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\chunk\\api.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChunkScore\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParserI\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mChunkParserI\u001b[39;00m(ParserI):\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    A processing interface for identifying non-overlapping groups in\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    unrestricted text.  Typically, chunk parsers are used to find base\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    will always generate a parse.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\parse\\__init__.py:100\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecursivedescent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     96\u001b[0m     RecursiveDescentParser,\n\u001b[0;32m     97\u001b[0m     SteppingRecursiveDescentParser,\n\u001b[0;32m     98\u001b[0m )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mshiftreduce\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ShiftReduceParser, SteppingShiftReduceParser\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransitionparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransitionParser\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TestGrammar, extract_test_sentences, load_parser\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mviterbi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ViterbiParser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\parse\\transitionparser.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m svm\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_svmlight_file\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\__init__.py:12\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# See http://scikit-learn.sourceforge.net/modules/svm.html for complete\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# documentation.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#         of their respective owners.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# License: BSD 3 clause (C) INRIA 2010\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bounds\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l1_min_c\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SVC, SVR, LinearSVC, LinearSVR, NuSVC, NuSVR, OneClassSVM\n\u001b[0;32m     14\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearSVC\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinearSVR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_min_c\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m ]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_classes.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, OutlierMixin, RegressorMixin, _fit_context\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearClassifierMixin, LinearModel, SparseCoefMixin\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, StrOptions\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\__init__.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ARDRegression, BayesianRidge\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_coordinate_descent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ElasticNet,\n\u001b[0;32m     11\u001b[0m     ElasticNetCV,\n\u001b[0;32m     12\u001b[0m     Lasso,\n\u001b[0;32m     13\u001b[0m     LassoCV,\n\u001b[0;32m     14\u001b[0m     MultiTaskElasticNet,\n\u001b[0;32m     15\u001b[0m     MultiTaskElasticNetCV,\n\u001b[0;32m     16\u001b[0m     MultiTaskLasso,\n\u001b[0;32m     17\u001b[0m     MultiTaskLassoCV,\n\u001b[0;32m     18\u001b[0m     enet_path,\n\u001b[0;32m     19\u001b[0m     lasso_path,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_glm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GammaRegressor, PoissonRegressor, TweedieRegressor\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_huber\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuberRegressor\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultiOutputMixin, RegressorMixin, _fit_context\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_cv\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch, check_array, check_scalar\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     MetadataRouter,\n\u001b[0;32m     24\u001b[0m     MethodMapping,\n\u001b[0;32m     25\u001b[0m     _raise_for_params,\n\u001b[0;32m     26\u001b[0m     get_routing_for_object,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Tools for model selection, such as cross validation and hyper-parameter tuning.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_classification_threshold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     FixedThresholdClassifier,\n\u001b[0;32m      7\u001b[0m     TunedThresholdClassifierCV,\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LearningCurveDisplay, ValidationCurveDisplay\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_search\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV, ParameterGrid, ParameterSampler, RandomizedSearchCV\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\model_selection\\_classification_threshold.py:14\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     BaseEstimator,\n\u001b[0;32m      8\u001b[0m     ClassifierMixin,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     clone,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     check_scoring,\n\u001b[0;32m     16\u001b[0m     get_scorer_names,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BaseScorer\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\metrics\\__init__.py:46\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_plot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mroc_curve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RocCurveDisplay\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ranking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     auc,\n\u001b[0;32m     34\u001b[0m     average_precision_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     top_k_accuracy_score,\n\u001b[0;32m     45\u001b[0m )\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_regression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     d2_absolute_error_score,\n\u001b[0;32m     48\u001b[0m     d2_pinball_score,\n\u001b[0;32m     49\u001b[0m     d2_tweedie_score,\n\u001b[0;32m     50\u001b[0m     explained_variance_score,\n\u001b[0;32m     51\u001b[0m     max_error,\n\u001b[0;32m     52\u001b[0m     mean_absolute_error,\n\u001b[0;32m     53\u001b[0m     mean_absolute_percentage_error,\n\u001b[0;32m     54\u001b[0m     mean_gamma_deviance,\n\u001b[0;32m     55\u001b[0m     mean_pinball_loss,\n\u001b[0;32m     56\u001b[0m     mean_poisson_deviance,\n\u001b[0;32m     57\u001b[0m     mean_squared_error,\n\u001b[0;32m     58\u001b[0m     mean_squared_log_error,\n\u001b[0;32m     59\u001b[0m     mean_tweedie_deviance,\n\u001b[0;32m     60\u001b[0m     median_absolute_error,\n\u001b[0;32m     61\u001b[0m     r2_score,\n\u001b[0;32m     62\u001b[0m     root_mean_squared_error,\n\u001b[0;32m     63\u001b[0m     root_mean_squared_log_error,\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_scorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_scoring, get_scorer, get_scorer_names, make_scorer\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     67\u001b[0m     adjusted_mutual_info_score,\n\u001b[0;32m     68\u001b[0m     adjusted_rand_score,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m     v_measure_score,\n\u001b[0;32m     83\u001b[0m )\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:846\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:941\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1039\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "\n",
    "# Step 2: Load medspaCy pipeline with ConText (negation handling)\n",
    "nlp = medspacy.load(\n",
    "    medspacy_enable=[\"medspacy_pyrush\", \"medspacy_target_matcher\", \"medspacy_context\"]\n",
    ")\n",
    "\n",
    "# Step 3: Define TargetRules with synonyms (PROBLEM entities only)\n",
    "problem_rules = [\n",
    "    TargetRule(\"stroke\", \"PROBLEM\"),\n",
    "    TargetRule(\"cerebrovascular accident\", \"PROBLEM\"),\n",
    "    TargetRule(\"diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"type 2 diabetes mellitus\", \"PROBLEM\"),\n",
    "    TargetRule(\"type ii diabetes mellitus\", \"PROBLEM\"),\n",
    "    TargetRule(\"type 2 diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"type ii diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"colon cancer\", \"PROBLEM\"),\n",
    "    TargetRule(\"colorectal carcinoma\", \"PROBLEM\"),\n",
    "    TargetRule(\"abdominal pain\", \"PROBLEM\"),\n",
    "    TargetRule(\"stomach ache\", \"PROBLEM\"),\n",
    "    TargetRule(\"metastasis\", \"PROBLEM\"),\n",
    "    TargetRule(\"tumor spread\", \"PROBLEM\"),\n",
    "    TargetRule(\"hypertension\", \"PROBLEM\"),\n",
    "    TargetRule(\"high blood pressure\", \"PROBLEM\"),\n",
    "    TargetRule(\"heart attack\", \"PROBLEM\"),\n",
    "    TargetRule(\"myocardial infarction\", \"PROBLEM\"),\n",
    "    TargetRule(\"asthma\", \"PROBLEM\"),\n",
    "    TargetRule(\"chronic obstructive pulmonary disease\", \"PROBLEM\"),\n",
    "    TargetRule(\"copd\", \"PROBLEM\"),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"tuberculosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"kidney failure\", \"PROBLEM\"),\n",
    "    TargetRule(\"renal failure\", \"PROBLEM\"),\n",
    "    TargetRule(\"liver cirrhosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"hepatitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"thyroid disorder\", \"PROBLEM\"),\n",
    "    TargetRule(\"hypothyroidism\", \"PROBLEM\"),\n",
    "    TargetRule(\"migraine\", \"PROBLEM\"),\n",
    "    TargetRule(\"epilepsy\", \"PROBLEM\"),\n",
    "]\n",
    "\n",
    "# Step 4: Add rules to the TargetMatcher\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_matcher.add(problem_rules)\n",
    "\n",
    "# Step 5: Problem-to-specialty mapping (multi-specialties allowed)\n",
    "problem_to_specialty = {\n",
    "    \"stroke\": [\"Neurologist\"],\n",
    "    \"cerebrovascular accident\": [\"Neurologist\"],\n",
    "    \"diabetes\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"type 2 diabetes mellitus\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"type ii diabetes mellitus\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"type 2 diabetes\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"type ii diabetes\": [\"Endocrinologist\", \"General Physician\"],\n",
    "    \"colon cancer\": [\"Oncologist\", \"Gastroenterologist\"],\n",
    "    \"colorectal carcinoma\": [\"Oncologist\", \"Gastroenterologist\"],\n",
    "    \"abdominal pain\": [\"Gastroenterologist\", \"General Physician\"],\n",
    "    \"stomach ache\": [\"Gastroenterologist\", \"General Physician\"],\n",
    "    \"metastasis\": [\"Oncologist\"],\n",
    "    \"tumor spread\": [\"Oncologist\"],\n",
    "    \"hypertension\": [\"Cardiologist\", \"General Physician\"],\n",
    "    \"high blood pressure\": [\"Cardiologist\", \"General Physician\"],\n",
    "    \"heart attack\": [\"Cardiologist\"],\n",
    "    \"myocardial infarction\": [\"Cardiologist\"],\n",
    "    \"asthma\": [\"Pulmonologist\"],\n",
    "    \"chronic obstructive pulmonary disease\": [\"Pulmonologist\"],\n",
    "    \"copd\": [\"Pulmonologist\"],\n",
    "    \"pneumonia\": [\"Pulmonologist\"],\n",
    "    \"tuberculosis\": [\"Pulmonologist\"],\n",
    "    \"kidney failure\": [\"Nephrologist\"],\n",
    "    \"renal failure\": [\"Nephrologist\"],\n",
    "    \"liver cirrhosis\": [\"Hepatologist\"],\n",
    "    \"hepatitis\": [\"Hepatologist\"],\n",
    "    \"thyroid disorder\": [\"Endocrinologist\"],\n",
    "    \"hypothyroidism\": [\"Endocrinologist\"],\n",
    "    \"migraine\": [\"Neurologist\"],\n",
    "    \"epilepsy\": [\"Neurologist\"],\n",
    "}\n",
    "\n",
    "# Synonym normalization mapping (for wider understanding)\n",
    "problem_synonyms = {\n",
    "    \"type 2 diabetes\": \"type 2 diabetes mellitus\",\n",
    "    \"type ii diabetes\": \"type ii diabetes mellitus\",\n",
    "    \"copd\": \"chronic obstructive pulmonary disease\",\n",
    "    \"tumor spread\": \"metastasis\",\n",
    "    \"stomach ache\": \"abdominal pain\",\n",
    "    \"high blood pressure\": \"hypertension\",\n",
    "    \"heart attack\": \"myocardial infarction\",\n",
    "}\n",
    "\n",
    "# Step 6: Specialist directory (expanded)\n",
    "specialist_directory = {\n",
    "    \"Neurologist\": {\n",
    "        \"name\": \"Dr. Alafiya Meditour\",\n",
    "        \"contact\": \"+91-9876543210\",\n",
    "        \"location\": \"Gurugram, Haryana\"\n",
    "    },\n",
    "    \"Endocrinologist\": {\n",
    "        \"name\": \"Dr. Anshul Kumar\",\n",
    "        \"contact\": \"+91-9123456780\",\n",
    "        \"location\": \"West Delhi, Delhi\"\n",
    "    },\n",
    "    \"General Physician\": {\n",
    "        \"name\": \"Dr. Renu Sharma\",\n",
    "        \"contact\": \"+91-9090909090\",\n",
    "        \"location\": \"Bengaluru, Karnataka\"\n",
    "    },\n",
    "    \"Oncologist\": {\n",
    "        \"name\": \"Dr. Amit Choraria\",\n",
    "        \"contact\": \"+91-9988776655\",\n",
    "        \"location\": \"Kolkata, West Bengal\"\n",
    "    },\n",
    "    \"Gastroenterologist\": {\n",
    "        \"name\": \"Dr. Bhartia Mithun\",\n",
    "        \"contact\": \"+91-9012345678\",\n",
    "        \"location\": \"Kamrup Metropolitan, Assam\"\n",
    "    },\n",
    "    \"Cardiologist\": {\n",
    "        \"name\": \"Dr. Priya Mehta\",\n",
    "        \"contact\": \"+91-9345678901\",\n",
    "        \"location\": \"Mumbai, Maharashtra\"\n",
    "    },\n",
    "    \"Pulmonologist\": {\n",
    "        \"name\": \"Dr. Sameer Bansal\",\n",
    "        \"contact\": \"+91-9456123789\",\n",
    "        \"location\": \"Jaipur, Rajasthan\"\n",
    "    },\n",
    "    \"Nephrologist\": {\n",
    "        \"name\": \"Dr. Kavita Deshmukh\",\n",
    "        \"contact\": \"+91-9988223344\",\n",
    "        \"location\": \"Chennai, Tamil Nadu\"\n",
    "    },\n",
    "    \"Hepatologist\": {\n",
    "        \"name\": \"Dr. Rajiv Kapoor\",\n",
    "        \"contact\": \"+91-9876501234\",\n",
    "        \"location\": \"Hyderabad, Telangana\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def normalize_problem(problem):\n",
    "    \"\"\"Normalize entity text for robust matching.\"\"\"\n",
    "    p = problem.strip().lower()\n",
    "    return problem_synonyms.get(p, p)\n",
    "\n",
    "# Step 7: Get user input\n",
    "text = input(\"Enter clinical text: \")\n",
    "\n",
    "# Step 8: Process the input text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Step 9: Extract valid PROBLEM entities (skip negated, normalize, deduplicate)\n",
    "problems = set()\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PROBLEM\":\n",
    "        if hasattr(ent._, \"is_negated\") and ent._.is_negated:\n",
    "            continue\n",
    "        normalized = normalize_problem(ent.text)\n",
    "        problems.add(normalized)\n",
    "\n",
    "# Step 10: Map problems to specialists and display results\n",
    "if not problems:\n",
    "    print(\"\\n No active problems detected from input.\")\n",
    "else:\n",
    "    for problem in sorted(problems):\n",
    "        specialties = problem_to_specialty.get(problem, [])\n",
    "        if specialties:\n",
    "            for specialty in specialties:\n",
    "                doctor = specialist_directory.get(specialty)\n",
    "                if doctor:\n",
    "                    print(f\"\\n Problem: {problem.title()}\")\n",
    "                    print(f\" Specialist: {specialty}\")\n",
    "                    print(f\" Doctor: {doctor['name']}\")\n",
    "                    print(f\" Contact: {doctor['contact']}\")\n",
    "                    print(f\" Location: {doctor['location']}\")\n",
    "        else:\n",
    "            print(f\"\\n No specialist found for problem: {problem.title()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49987844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import medspacy\n",
    "from medspacy.ner import TargetRule\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81bd75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load(\n",
    "    medspacy_enable=[\"medspacy_pyrush\", \"medspacy_target_matcher\", \"medspacy_context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a3f3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_rules = [\n",
    "    # Neurological disorders\n",
    "    TargetRule(\"stroke\", \"PROBLEM\"),\n",
    "    TargetRule(\"cerebrovascular accident\", \"PROBLEM\"),\n",
    "    TargetRule(\"CVA\", \"PROBLEM\"),\n",
    "    TargetRule(\"migraine\", \"PROBLEM\"),\n",
    "    TargetRule(\"headache\", \"PROBLEM\"),\n",
    "    TargetRule(\"epilepsy\", \"PROBLEM\"),\n",
    "    TargetRule(\"seizure\", \"PROBLEM\"),\n",
    "    TargetRule(\"parkinson\", \"PROBLEM\"),\n",
    "    TargetRule(\"alzheimer\", \"PROBLEM\"),\n",
    "    TargetRule(\"dementia\", \"PROBLEM\"),\n",
    "    TargetRule(\"multiple sclerosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"neuropathy\", \"PROBLEM\"),\n",
    "    TargetRule(\"bell's palsy\", \"PROBLEM\"),\n",
    "    \n",
    "    # Endocrine disorders\n",
    "    TargetRule(\"diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"type 1 diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"type 2 diabetes\", \"PROBLEM\"),\n",
    "    TargetRule(\"diabetes mellitus\", \"PROBLEM\"),\n",
    "    TargetRule(\"hypothyroidism\", \"PROBLEM\"),\n",
    "    TargetRule(\"hyperthyroidism\", \"PROBLEM\"),\n",
    "    TargetRule(\"thyroid disorder\", \"PROBLEM\"),\n",
    "    TargetRule(\"goiter\", \"PROBLEM\"),\n",
    "    TargetRule(\"pcos\", \"PROBLEM\"),\n",
    "    TargetRule(\"polycystic ovary syndrome\", \"PROBLEM\"),\n",
    "    TargetRule(\"obesity\", \"PROBLEM\"),\n",
    "    TargetRule(\"metabolic syndrome\", \"PROBLEM\"),\n",
    "    \n",
    "    # Gastrointestinal disorders\n",
    "    TargetRule(\"colon cancer\", \"PROBLEM\"),\n",
    "    TargetRule(\"colorectal carcinoma\", \"PROBLEM\"),\n",
    "    TargetRule(\"abdominal pain\", \"PROBLEM\"),\n",
    "    TargetRule(\"stomach ache\", \"PROBLEM\"),\n",
    "    TargetRule(\"gerd\", \"PROBLEM\"),\n",
    "    TargetRule(\"acid reflux\", \"PROBLEM\"),\n",
    "    TargetRule(\"ibs\", \"PROBLEM\"),\n",
    "    TargetRule(\"irritable bowel syndrome\", \"PROBLEM\"),\n",
    "    TargetRule(\"crohn's disease\", \"PROBLEM\"),\n",
    "    TargetRule(\"ulcerative colitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"gallstones\", \"PROBLEM\"),\n",
    "    TargetRule(\"cholecystitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"pancreatitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"hepatitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"liver cirrhosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"jaundice\", \"PROBLEM\"),\n",
    "    \n",
    "    # Cardiovascular disorders\n",
    "    TargetRule(\"hypertension\", \"PROBLEM\"),\n",
    "    TargetRule(\"high blood pressure\", \"PROBLEM\"),\n",
    "    TargetRule(\"heart attack\", \"PROBLEM\"),\n",
    "    TargetRule(\"myocardial infarction\", \"PROBLEM\"),\n",
    "    TargetRule(\"MI\", \"PROBLEM\"),\n",
    "    TargetRule(\"angina\", \"PROBLEM\"),\n",
    "    TargetRule(\"arrhythmia\", \"PROBLEM\"),\n",
    "    TargetRule(\"heart failure\", \"PROBLEM\"),\n",
    "    TargetRule(\"coronary artery disease\", \"PROBLEM\"),\n",
    "    TargetRule(\"CAD\", \"PROBLEM\"),\n",
    "    TargetRule(\"cardiomyopathy\", \"PROBLEM\"),\n",
    "    \n",
    "    # Respiratory disorders\n",
    "    TargetRule(\"asthma\", \"PROBLEM\"),\n",
    "    TargetRule(\"COPD\", \"PROBLEM\"),\n",
    "    TargetRule(\"chronic obstructive pulmonary disease\", \"PROBLEM\"),\n",
    "    TargetRule(\"pneumonia\", \"PROBLEM\"),\n",
    "    TargetRule(\"tuberculosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"TB\", \"PROBLEM\"),\n",
    "    TargetRule(\"bronchitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"sinusitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"allergic rhinitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"sleep apnea\", \"PROBLEM\"),\n",
    "    \n",
    "    # Renal disorders\n",
    "    TargetRule(\"kidney failure\", \"PROBLEM\"),\n",
    "    TargetRule(\"renal failure\", \"PROBLEM\"),\n",
    "    TargetRule(\"kidney stones\", \"PROBLEM\"),\n",
    "    TargetRule(\"nephrolithiasis\", \"PROBLEM\"),\n",
    "    TargetRule(\"UTI\", \"PROBLEM\"),\n",
    "    TargetRule(\"urinary tract infection\", \"PROBLEM\"),\n",
    "    TargetRule(\"cystitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"pyelonephritis\", \"PROBLEM\"),\n",
    "    \n",
    "    # Oncology\n",
    "    TargetRule(\"metastasis\", \"PROBLEM\"),\n",
    "    TargetRule(\"tumor spread\", \"PROBLEM\"),\n",
    "    TargetRule(\"cancer\", \"PROBLEM\"),\n",
    "    TargetRule(\"carcinoma\", \"PROBLEM\"),\n",
    "    TargetRule(\"leukemia\", \"PROBLEM\"),\n",
    "    TargetRule(\"lymphoma\", \"PROBLEM\"),\n",
    "    TargetRule(\"melanoma\", \"PROBLEM\"),\n",
    "    \n",
    "    # Musculoskeletal disorders\n",
    "    TargetRule(\"arthritis\", \"PROBLEM\"),\n",
    "    TargetRule(\"osteoarthritis\", \"PROBLEM\"),\n",
    "    TargetRule(\"rheumatoid arthritis\", \"PROBLEM\"),\n",
    "    TargetRule(\"back pain\", \"PROBLEM\"),\n",
    "    TargetRule(\"sciatica\", \"PROBLEM\"),\n",
    "    TargetRule(\"osteoporosis\", \"PROBLEM\"),\n",
    "    TargetRule(\"gout\", \"PROBLEM\"),\n",
    "    TargetRule(\"carpal tunnel syndrome\", \"PROBLEM\"),\n",
    "    \n",
    "    # Dermatological disorders\n",
    "    TargetRule(\"eczema\", \"PROBLEM\"),\n",
    "    TargetRule(\"psoriasis\", \"PROBLEM\"),\n",
    "    TargetRule(\"acne\", \"PROBLEM\"),\n",
    "    TargetRule(\"rosacea\", \"PROBLEM\"),\n",
    "    TargetRule(\"skin infection\", \"PROBLEM\"),\n",
    "    TargetRule(\"cellulitis\", \"PROBLEM\"),\n",
    "    \n",
    "    # Ophthalmology\n",
    "    TargetRule(\"cataract\", \"PROBLEM\"),\n",
    "    TargetRule(\"glaucoma\", \"PROBLEM\"),\n",
    "    TargetRule(\"macular degeneration\", \"PROBLEM\"),\n",
    "    TargetRule(\"conjunctivitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"dry eye\", \"PROBLEM\"),\n",
    "    \n",
    "    # ENT\n",
    "    TargetRule(\"otitis media\", \"PROBLEM\"),\n",
    "    TargetRule(\"ear infection\", \"PROBLEM\"),\n",
    "    TargetRule(\"tonsillitis\", \"PROBLEM\"),\n",
    "    TargetRule(\"sinus infection\", \"PROBLEM\"),\n",
    "    TargetRule(\"hearing loss\", \"PROBLEM\"),\n",
    "    TargetRule(\"tinnitus\", \"PROBLEM\"),\n",
    "    \n",
    "    # Mental health\n",
    "    TargetRule(\"depression\", \"PROBLEM\"),\n",
    "    TargetRule(\"anxiety\", \"PROBLEM\"),\n",
    "    TargetRule(\"bipolar disorder\", \"PROBLEM\"),\n",
    "    TargetRule(\"schizophrenia\", \"PROBLEM\"),\n",
    "    TargetRule(\"PTSD\", \"PROBLEM\"),\n",
    "    TargetRule(\"post-traumatic stress disorder\", \"PROBLEM\"),\n",
    "    \n",
    "    # Other common conditions\n",
    "    TargetRule(\"anemia\", \"PROBLEM\"),\n",
    "    TargetRule(\"vitamin deficiency\", \"PROBLEM\"),\n",
    "    TargetRule(\"dehydration\", \"PROBLEM\"),\n",
    "    TargetRule(\"allergy\", \"PROBLEM\"),\n",
    "    TargetRule(\"food poisoning\", \"PROBLEM\"),\n",
    "    TargetRule(\"constipation\", \"PROBLEM\"),\n",
    "    TargetRule(\"diarrhea\", \"PROBLEM\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08936f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Add rules to the TargetMatcher\n",
    "target_matcher = nlp.get_pipe(\"medspacy_target_matcher\")\n",
    "target_matcher.add(problem_rules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e36b2830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Enhanced problem-to-specialty mapping with pattern matching\n",
    "def map_problem_to_specialty(problem_text):\n",
    "    problem_text = problem_text.lower()\n",
    "    \n",
    "    # Neurological disorders\n",
    "    if any(term in problem_text for term in [\"stroke\", \"cva\", \"cerebrovascular\", \"migraine\", \"headache\", \n",
    "                                           \"epilepsy\", \"seizure\", \"parkinson\", \"alzheimer\", \"dementia\", \n",
    "                                           \"multiple sclerosis\", \"neuropathy\", \"bell's palsy\"]):\n",
    "        return [\"Neurologist\"]\n",
    "    \n",
    "    # Endocrine disorders\n",
    "    elif any(term in problem_text for term in [\"diabetes\", \"thyroid\", \"goiter\", \"pcos\", \"polycystic ovary\", \n",
    "                                             \"obesity\", \"metabolic syndrome\"]):\n",
    "        return [\"Endocrinologist\", \"General Physician\"]\n",
    "    \n",
    "    # Gastrointestinal disorders\n",
    "    elif any(term in problem_text for term in [\"colon\", \"colorectal\", \"abdominal\", \"stomach\", \"gerd\", \n",
    "                                             \"acid reflux\", \"ibs\", \"irritable bowel\", \"crohn\", \"colitis\", \n",
    "                                             \"gallstone\", \"cholecystitis\", \"pancreatitis\", \"hepatitis\", \n",
    "                                             \"liver\", \"jaundice\"]):\n",
    "        specialties = [\"Gastroenterologist\"]\n",
    "        if any(term in problem_text for term in [\"cancer\", \"carcinoma\"]):\n",
    "            specialties.append(\"Oncologist\")\n",
    "        if \"pain\" in problem_text or \"ache\" in problem_text:\n",
    "            specialties.append(\"General Physician\")\n",
    "        return specialties\n",
    "    \n",
    "    # Cardiovascular disorders\n",
    "    elif any(term in problem_text for term in [\"hypertension\", \"blood pressure\", \"heart\", \"myocardial\", \n",
    "                                             \"angina\", \"arrhythmia\", \"coronary\", \"cardiomyopathy\"]):\n",
    "        return [\"Cardiologist\", \"General Physician\"]\n",
    "    \n",
    "    # Respiratory disorders\n",
    "    elif any(term in problem_text for term in [\"asthma\", \"copd\", \"pulmonary\", \"pneumonia\", \"tuberculosis\", \n",
    "                                             \"tb\", \"bronchitis\", \"sinusitis\", \"rhinitis\", \"sleep apnea\"]):\n",
    "        return [\"Pulmonologist\", \"General Physician\"]\n",
    "    \n",
    "    # Renal disorders\n",
    "    elif any(term in problem_text for term in [\"kidney\", \"renal\", \"nephro\", \"uti\", \"urinary\", \"cystitis\", \n",
    "                                             \"pyelonephritis\"]):\n",
    "        return [\"Nephrologist\", \"Urologist\"]\n",
    "    \n",
    "    # Oncology\n",
    "    elif any(term in problem_text for term in [\"cancer\", \"carcinoma\", \"metastasis\", \"tumor\", \"leukemia\", \n",
    "                                             \"lymphoma\", \"melanoma\"]):\n",
    "        specialties = [\"Oncologist\"]\n",
    "        if any(term in problem_text for term in [\"breast\", \"colon\", \"colorectal\", \"prostate\"]):\n",
    "            specialties.append(\"Surgical Oncologist\")\n",
    "        return specialties\n",
    "    \n",
    "    # Musculoskeletal disorders\n",
    "    elif any(term in problem_text for term in [\"arthritis\", \"osteoarthritis\", \"rheumatoid\", \"back pain\", \n",
    "                                             \"sciatica\", \"osteoporosis\", \"gout\", \"carpal tunnel\"]):\n",
    "        return [\"Orthopedist\", \"Rheumatologist\"]\n",
    "    \n",
    "    # Dermatological disorders\n",
    "    elif any(term in problem_text for term in [\"eczema\", \"psoriasis\", \"acne\", \"rosacea\", \"skin infection\", \n",
    "                                             \"cellulitis\"]):\n",
    "        return [\"Dermatologist\"]\n",
    "    \n",
    "    # Ophthalmology\n",
    "    elif any(term in problem_text for term in [\"cataract\", \"glaucoma\", \"macular\", \"conjunctivitis\", \"dry eye\"]):\n",
    "        return [\"Ophthalmologist\"]\n",
    "    \n",
    "    # ENT\n",
    "    elif any(term in problem_text for term in [\"otitis\", \"ear infection\", \"tonsillitis\", \"sinus infection\", \n",
    "                                             \"hearing loss\", \"tinnitus\"]):\n",
    "        return [\"ENT Specialist\"]\n",
    "    \n",
    "    # Mental health\n",
    "    elif any(term in problem_text for term in [\"depression\", \"anxiety\", \"bipolar\", \"schizophrenia\", \"ptsd\", \n",
    "                                             \"post-traumatic stress\"]):\n",
    "        return [\"Psychiatrist\"]\n",
    "    \n",
    "    # Other common conditions\n",
    "    elif any(term in problem_text for term in [\"anemia\", \"vitamin deficiency\"]):\n",
    "        return [\"General Physician\", \"Hematologist\"]\n",
    "    elif any(term in problem_text for term in [\"dehydration\", \"food poisoning\", \"constipation\", \"diarrhea\"]):\n",
    "        return [\"General Physician\"]\n",
    "    elif \"allergy\" in problem_text:\n",
    "        return [\"Allergist\", \"General Physician\"]\n",
    "    \n",
    "    return [\"General Physician\"]\n",
    "\n",
    "# Step 6: Expanded specialist directory\n",
    "specialist_directory = {\n",
    "    \"Neurologist\": {\n",
    "        \"name\": \"Dr. Alafiya Meditour\",\n",
    "        \"contact\": \"+91-9876543210\",\n",
    "        \"location\": \"Gurugram, Haryana\",\n",
    "        \"specialization\": \"Neurology, Stroke, Epilepsy\"\n",
    "    },\n",
    "    \"Endocrinologist\": {\n",
    "        \"name\": \"Dr. Anshul Kumar\",\n",
    "        \"contact\": \"+91-9123456780\",\n",
    "        \"location\": \"West Delhi, Delhi\",\n",
    "        \"specialization\": \"Diabetes, Thyroid Disorders, Hormonal Issues\"\n",
    "    },\n",
    "    \"General Physician\": {\n",
    "        \"name\": \"Dr. Renu Sharma\",\n",
    "        \"contact\": \"+91-9090909090\",\n",
    "        \"location\": \"Bengaluru, Karnataka\",\n",
    "        \"specialization\": \"General Medicine, Common Ailments\"\n",
    "    },\n",
    "    \"Oncologist\": {\n",
    "        \"name\": \"Dr. Amit Choraria\",\n",
    "        \"contact\": \"+91-9988776655\",\n",
    "        \"location\": \"Kolkata, West Bengal\",\n",
    "        \"specialization\": \"Cancer Treatment, Chemotherapy\"\n",
    "    },\n",
    "    \"Gastroenterologist\": {\n",
    "        \"name\": \"Dr. Bhartia Mithun\",\n",
    "        \"contact\": \"+91-9012345678\",\n",
    "        \"location\": \"Kamrup Metropolitan, Assam\",\n",
    "        \"specialization\": \"Digestive Disorders, Endoscopy\"\n",
    "    },\n",
    "    \"Cardiologist\": {\n",
    "        \"name\": \"Dr. Priya Mehta\",\n",
    "        \"contact\": \"+91-9345678901\",\n",
    "        \"location\": \"Mumbai, Maharashtra\",\n",
    "        \"specialization\": \"Heart Diseases, Hypertension\"\n",
    "    },\n",
    "    \"Pulmonologist\": {\n",
    "        \"name\": \"Dr. Sameer Bansal\",\n",
    "        \"contact\": \"+91-9456123789\",\n",
    "        \"location\": \"Jaipur, Rajasthan\",\n",
    "        \"specialization\": \"Respiratory Diseases, Asthma, COPD\"\n",
    "    },\n",
    "    \"Nephrologist\": {\n",
    "        \"name\": \"Dr. Kavita Deshmukh\",\n",
    "        \"contact\": \"+91-9988223344\",\n",
    "        \"location\": \"Chennai, Tamil Nadu\",\n",
    "        \"specialization\": \"Kidney Diseases, Dialysis\"\n",
    "    },\n",
    "    \"Urologist\": {\n",
    "        \"name\": \"Dr. Rajesh Malhotra\",\n",
    "        \"contact\": \"+91-9765432109\",\n",
    "        \"location\": \"Ahmedabad, Gujarat\",\n",
    "        \"specialization\": \"Urinary Tract Disorders, Kidney Stones\"\n",
    "    },\n",
    "    \"Hepatologist\": {\n",
    "        \"name\": \"Dr. Rajiv Kapoor\",\n",
    "        \"contact\": \"+91-9876501234\",\n",
    "        \"location\": \"Hyderabad, Telangana\",\n",
    "        \"specialization\": \"Liver Diseases, Hepatitis\"\n",
    "    },\n",
    "    \"Orthopedist\": {\n",
    "        \"name\": \"Dr. Vikram Singh\",\n",
    "        \"contact\": \"+91-9333444555\",\n",
    "        \"location\": \"Pune, Maharashtra\",\n",
    "        \"specialization\": \"Bone and Joint Disorders, Fractures\"\n",
    "    },\n",
    "    \"Rheumatologist\": {\n",
    "        \"name\": \"Dr. Meena Patel\",\n",
    "        \"contact\": \"+91-9111222333\",\n",
    "        \"location\": \"Chandigarh\",\n",
    "        \"specialization\": \"Arthritis, Autoimmune Disorders\"\n",
    "    },\n",
    "    \"Dermatologist\": {\n",
    "        \"name\": \"Dr. Sunita Reddy\",\n",
    "        \"contact\": \"+91-9555666777\",\n",
    "        \"location\": \"Kochi, Kerala\",\n",
    "        \"specialization\": \"Skin Diseases, Cosmetic Dermatology\"\n",
    "    },\n",
    "    \"Ophthalmologist\": {\n",
    "        \"name\": \"Dr. Arvind Joshi\",\n",
    "        \"contact\": \"+91-9444455555\",\n",
    "        \"location\": \"Bhopal, Madhya Pradesh\",\n",
    "        \"specialization\": \"Eye Diseases, Cataract Surgery\"\n",
    "    },\n",
    "    \"ENT Specialist\": {\n",
    "        \"name\": \"Dr. Sanjay Gupta\",\n",
    "        \"contact\": \"+91-9777788888\",\n",
    "        \"location\": \"Lucknow, Uttar Pradesh\",\n",
    "        \"specialization\": \"Ear, Nose and Throat Disorders\"\n",
    "    },\n",
    "    \"Psychiatrist\": {\n",
    "        \"name\": \"Dr. Anjali Mehta\",\n",
    "        \"contact\": \"+91-9666677777\",\n",
    "        \"location\": \"Dehradun, Uttarakhand\",\n",
    "        \"specialization\": \"Mental Health, Depression, Anxiety\"\n",
    "    },\n",
    "    \"Allergist\": {\n",
    "        \"name\": \"Dr. Rohit Verma\",\n",
    "        \"contact\": \"+91-9888899999\",\n",
    "        \"location\": \"Nagpur, Maharashtra\",\n",
    "        \"specialization\": \"Allergies, Immune Disorders\"\n",
    "    },\n",
    "    \"Hematologist\": {\n",
    "        \"name\": \"Dr. Neha Sharma\",\n",
    "        \"contact\": \"+91-9222233333\",\n",
    "        \"location\": \"Patna, Bihar\",\n",
    "        \"specialization\": \"Blood Disorders, Anemia\"\n",
    "    },\n",
    "    \"Surgical Oncologist\": {\n",
    "        \"name\": \"Dr. Karan Malhotra\",\n",
    "        \"contact\": \"+91-9333344444\",\n",
    "        \"location\": \"Jaipur, Rajasthan\",\n",
    "        \"specialization\": \"Cancer Surgery, Tumor Removal\"\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1df10c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input(\"Enter clinical text or symptoms: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd92d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-09 11:35:06.646\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=7] [doc 0] Token 0 'stroke' marked as sentence start (span begin)\u001b[0m\n",
      "\u001b[32m2025-09-09 11:35:06.647\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mPyRuSH.PyRuSHSentencizer\u001b[0m:\u001b[36mpredict\u001b[0m:\u001b[36m100\u001b[0m - \u001b[34m\u001b[1m[cpredict_split_gaps|call_id=7] Token/tag mapping: [(stroke, True)]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4ed4e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Extract valid PROBLEM entities (skip negated)\n",
    "problems = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PROBLEM\":\n",
    "        if hasattr(ent._, \"is_negated\") and ent._.is_negated:\n",
    "            continue\n",
    "        problems.append(ent.text.lower())\n",
    "\n",
    "# If no entities found, try to extract symptoms using simple pattern matching\n",
    "if not problems:\n",
    "    symptom_patterns = [\n",
    "        r\"(pain|ache|discomfort) (in|of|around) (the )?(\\w+)\",\n",
    "        r\"(difficulty|trouble|problem) (with|in) (\\w+)\",\n",
    "        r\"(swollen|swelling|inflamed) (\\w+)\",\n",
    "        r\"(numbness|tingling) (in|of) (the )?(\\w+)\",\n",
    "        r\"(rash|redness|itching) (on|in) (the )?(\\w+)\",\n",
    "        r\"(fever|headache|cough|sneeze|vomit|nausea|dizziness|fatigue|weakness)\"\n",
    "    ]\n",
    "    \n",
    "    for pattern in symptom_patterns:\n",
    "        matches = re.finditer(pattern, text.lower())\n",
    "        for match in matches:\n",
    "            problems.append(match.group(0))\n",
    "\n",
    "# Remove duplicates\n",
    "problems = list(set(problems))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0934c6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Detected 1 problem(s): Stroke\n",
      "\n",
      " Recommended specialists:\n",
      "\n",
      " Specialty: Neurologist\n",
      " Doctor: Dr. Alafiya Meditour\n",
      " Contact: +91-9876543210\n",
      " Location: Gurugram, Haryana\n",
      " Specialization: Neurology, Stroke, Epilepsy\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Map problems to specialists and display results\n",
    "if not problems:\n",
    "    print(\"\\n No specific problems detected from input.\")\n",
    "    print(\" Recommended: Consult a General Physician\")\n",
    "    doctor = specialist_directory.get(\"General Physician\")\n",
    "    print(f\" Doctor: {doctor['name']}\")\n",
    "    print(f\" Contact: {doctor['contact']}\")\n",
    "    print(f\" Location: {doctor['location']}\")\n",
    "    print(f\" Specialization: {doctor['specialization']}\")\n",
    "else:\n",
    "    print(f\"\\n Detected {len(problems)} problem(s): {', '.join([p.title() for p in problems])}\")\n",
    "    \n",
    "    # Collect all recommended specialties\n",
    "    all_specialties = set()\n",
    "    for problem in problems:\n",
    "        specialties = map_problem_to_specialty(problem)\n",
    "        all_specialties.update(specialties)\n",
    "    \n",
    "    # Display recommendations\n",
    "    if all_specialties:\n",
    "        print(\"\\n Recommended specialists:\")\n",
    "        for specialty in all_specialties:\n",
    "            doctor = specialist_directory.get(specialty)\n",
    "            if doctor:\n",
    "                print(f\"\\n Specialty: {specialty}\")\n",
    "                print(f\" Doctor: {doctor['name']}\")\n",
    "                print(f\" Contact: {doctor['contact']}\")\n",
    "                print(f\" Location: {doctor['location']}\")\n",
    "                print(f\" Specialization: {doctor['specialization']}\")\n",
    "    else:\n",
    "        print(\"\\n Recommended: Consult a General Physician\")\n",
    "        doctor = specialist_directory.get(\"General Physician\")\n",
    "        print(f\" Doctor: {doctor['name']}\")\n",
    "        print(f\" Contact: {doctor['contact']}\")\n",
    "        print(f\" Location: {doctor['location']}\")\n",
    "        print(f\" Specialization: {doctor['specialization']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98166e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015b818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
